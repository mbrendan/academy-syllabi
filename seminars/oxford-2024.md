# Oxford 2024: AI x Philosophy Seminar

**Format:** Academic seminar
**Duration:** 8 weeks (Trinity Term 2024)
**Location:** University of Oxford
**Instructors:** Philipp Koralus (Oxford) and Brendan McCord (Cosmos Institute)

---

## Overview

Co-taught by Professor Philipp Koralus and Brendan McCord, Visiting Fellow at St. Catherine's College, this seminar explores issues at the intersection of philosophy, AI, and technological innovation. Distinguished visitors from the technology industry bring insights from Midjourney, Anthropic, Imbue, Google DeepMind, Story Protocol, ex/ante, and Stripe.

The focus is on how a concern for human flourishing can be embedded in the global technology development pipeline from the ground up, and on exploring how broader bridges can be built between philosophy and technology.

---

## Guiding Question

> "We have a duty to be optimistic. Because the future is open, not predetermined and therefore cannot just be accepted: we are all responsible for what it holds. Thus it is our duty to fight for a better world."
> — David Deutsch

AI has opened a new continent, and humanity is setting foot on its shores. How we reaffirm principles of human flourishing in light of the coming innovations will be crucial. What is the conceptual structure of the problem of translating conceptions of human flourishing into AI technology? One important aspect of human flourishing is **freedom**—but what notion of freedom? How can the best notion of freedom be realised in practice in our technological age?

---

## Syllabus

### Week 1: Perspectives on AI and Human Flourishing

**Readings:**
- Koralus, P. *Reason and Inquiry: The Erotetic Theory*, OUP, sections 1.3, 6.7, 6.8
- Hayek, F. *The Constitution of Liberty*, University of Chicago Press, Ch. 1, pp. 57-72
- Pettit, P. *Republicanism: A Theory of Freedom and Government*, Ch. 2, pp. 51-73
- Berlin, I. "Two Concepts of Liberty," in *Four Essays on Liberty*, sections I, II, and III

---

### Week 2: AI, Reasoning, and Agency

**Visitor:** Matt Boulos, Policy and Safety Lead, Imbue, San Francisco

When we say that a large language model can "reason," we're saying a curious thing: instead of predicting an answer right away, the model predicts a logical sequence that leads to an answer. This understanding is liberating—it shows us that the model is not operating in some realm beyond our understanding and that we can deliberately shape reasoning sequences to get the results we want. The tricky part is knowing what we want.

**Readings:**
- Koralus, P. "Why AI still isn't getting into Oxford, and why that shows it is astounding." WIRED Italia, March 2024
- Huang, J. et al. "Large Language Models Cannot Self-Correct Reasoning Yet"
- Turpin, M. et al. "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting"
- Lazar, S. "Legitimacy, Authority, and Democratic Duties of Explanation"

---

### Week 3: Blockchain, Liberty, and Political Philosophy

**Visitor:** Jason Zhao, Cofounder, Story Protocol, San Francisco

We live in an era of centralising tendencies, largely driven by technological capacity. Do blockchain technologies represent a potential technological antidote to these risks? This lecture covers the visions of the early cypherpunks, as well as their contemporary adherents. From immutable money to networked states, we discuss the divergent political philosophies behind blockchain.

**Readings:**
- Mansfield, H. *Tocqueville: A Very Short Introduction*, OUP, Ch. 4, pp. 57-83
- Nakamoto, S. "Bitcoin whitepaper"
- Balaji, S. "The Network State in One Essay"
- Hayek, F. "The Use of Knowledge in Society"

---

### Week 4: A Model for Parity and Its Relevance to AI

**Visitors:** Kit Fine (New York University); Ruth Chang (University of Oxford)

We propose a model of parity in terms of approximate differences and approximate quotients and show how it can be used to facilitate communication between AI and its users when hard choices need to be made.

**Readings:**
- Chang, R. "Hard Choices"
- Chang, R. "Human in the Loop!" in *AI Morality*, ed. Dave Edmonds, OUP

---

### Week 5: Public Deliberation and the Correction of Collective Errors

For Publius of the Federalist Papers, public deliberation requires that "the cool and deliberate sense of the community ought, in all governments, and actually will, in all free governments, ultimately prevail over the views of its rulers." We examine the fate of this standard under AI, assessing both a critical approach and a more positive vision for its potential renaissance.

**Readings:**
- Polanyi, M. "Republic of Science: Its Political and Economy Theory"
- Mill, J.S. *On Liberty*, EconLib, Ch. 2
- Coeckelbergh, M. "Democracy, epistemic agency, and AI: political epistemology in times of artificial intelligence"

---

### Week 6: Recommender Systems, Human Agency, and Collective Intelligence

**Visitor:** Ivan Vendrov, Researcher, Midjourney, NYC

As a social species, key aspects of human flourishing depend upon our relation to the collective. How can we build technologies that help human groups communicate and act together? Language models seem poised to be more important than the printing press in changing the information architecture of society, with major consequences for politics, religion, and human flourishing.

**Readings:**
- Stray, J., Vendrov, I., et al. "What are you optimizing for? Aligning Recommender Systems with Human Values"
- Christiano, P. "What failure looks like"
- Jordan, M.I. "Dr. AI or: How I Learned to Stop Worrying and Love Economics"

---

### Week 7: Human Learning and AI Tutors

**Visitor:** Michael Strong, Founder, Socratic Experience, Austin

If we recognise the extent to which human beings are genetically programmed to be cultural creatures, issues associated with AI and learning become much more interesting than usually recognized. We must consider the cultural embeddedness of learning and how to optimise learning for differing cultural contexts.

**Readings:**
- Henrich, J. "A Cultural Species: Why a theory of culture is required to build a science of human behavior," pp. 25-30
- Karlsson, H. "AI tutors will be held back by culture"
- Gatto, J.T. "The Seven Lesson Schoolteacher"

---

### Week 8: Agentic Tech and Countering Digital Authoritarianism / The Power of Open-Ended Systems

**Part 1 Visitor:** Zoe Weinberg, Founder & Managing Partner, ex/ante, NYC
**Part 2 Visitor:** Alex Komoroske, former Head of Corporate Strategy, Stripe, San Francisco

Part 1 examines technological developments that have progressively stripped individuals of agency and the authoritarian consequences, including the "agentic tech" movement seeking to prioritise human agency.

Part 2 considers systems that are alive and escape the control of their creator—open-ended systems that can achieve outcomes none of the participants ever imagined.

**Readings:**
- Weinberg, Z. "Agentic tech to counter digital authoritarianism" (2023)
- Estrin, J. "Authoritarian Technology: Attention!"
- Nissenbaum, H. "Privacy as contextual integrity"
- Tang, A., Weyl, G. *Plurality*, Parts 1 and 2 (Preface & Introduction)
- Komoroske, A. "The Meaning of Open"
- Brander, G. "Aggregators aren't open-ended"

---

## Visitor Biographies

**Matt Boulos** leads policy and safety at Imbue. He's a lawyer, computer scientist, and founder of Canada's first anonymous online legal service. Bachelor's in Computer Science and International Relations from University of Toronto; JD from Harvard Law School.

**Jason Zhao** is co-founder of Story Protocol. Former Product Manager at DeepMind, inaugural John Stuart Mill Fellow at Mercatus Center. Bachelor's in Philosophy and Master's in Computer Science from Stanford.

**Kit Fine** is University Professor and Silver Professor of Philosophy and Mathematics at New York University. Fellow of the American Academy of Arts and Sciences and British Academy.

**Ruth Chang** is Chair of Jurisprudence at the University of Oxford. Research concerns normativity, values, practical reason, decision-making, and the self.

**Ivan Vendrov** leads collective intelligence at Midjourney. Previously at Anthropic, Google Research, and University of Toronto.

**Michael Strong** is founder of Socratic Experience. Author of *The Habit of Thought: From Socratic Seminars to Socratic Practice*.

**Zoe Weinberg** is founder of ex/ante, an early-stage venture fund for agentic tech. Previously served on the National Security Commission on Artificial Intelligence and at Google AI. MBA from Stanford, JD from Yale.

**Alex Komoroske** is founder of a stealth startup reimagining the web for AI. Previously Head of Corporate Strategy at Stripe and led Chrome's Open Web Platform team at Google.

---

## Instructor Biographies

**Philipp Koralus** is the Fulford Clarendon Professor of Philosophy and Cognitive Science at the University of Oxford. He studies human reasoning and decision-making and how it relates to artificial agents and large language models. Author of *Reason and Inquiry*. Senior Research Associate at the Institute for Ethics in AI.

**Brendan McCord** is founder and Chair of Cosmos Institute and Visiting Fellow at St. Catherine's College. Founding CEO of two AI startups acquired for $400 million, principal founder of the first DoD applied AI organization. SB from MIT, MBA from Harvard.
